{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# GPU: CuPy, Numba-GPU, PyCUDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "If you can get better memory efficiency using rowwise code (e.g. compiled for loops), why would you ever write columnar code (e.g. Numpy)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** vectorization!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vectorization is a vertical scaling technique that uses a single CPU core or a GPU more effectively. You can compute N operations at the same time _if they are all the same operation._\n",
    "\n",
    "<center><img src=\"img/vectorization-example.png\" width=\"50%\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you don't fully utilize all cores, that's okay; someone else's work can fill the gaps.\n",
    "\n",
    "If you don't fully utilize the core's vector unit, no one else can use them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A GPU is a computational device designed around vector units."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Like parallel processing, this is another computing detail that is visible to you as a data analyst. Rowwise code like\n",
    "\n",
    "```python\n",
    "@numba.jit\n",
    "def run_numba_loop(height, width, maxiterations, c, fractal):\n",
    "    for h in range(height):\n",
    "        for w in range(width):\n",
    "            z = c[h, w]\n",
    "            for i in range(maxiterations):\n",
    "                z = z**2 + c[h, w]\n",
    "                if abs(z) > 2:\n",
    "                    fractal[h, w] = i\n",
    "                    break\n",
    "    return fractal\n",
    "```\n",
    "\n",
    "does not use vector units effectively because each array element may be in a different stage of processingâ€” some may have diverged before others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Columnar code like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import time\n",
    "\n",
    "def prepare(height, width):\n",
    "    y, x = numpy.ogrid[-1:0:height*1j, -1.5:0:width*1j]\n",
    "    c = x + y*1j\n",
    "    fractal = numpy.zeros(c.shape, dtype=numpy.int32)\n",
    "    return c, fractal\n",
    "\n",
    "def run(c, fractal, maxiterations=20):\n",
    "    fractal *= 0                  # set fractal to maxiterations without replacing it\n",
    "    fractal += maxiterations\n",
    "    z = c\n",
    "    for i in range(maxiterations):\n",
    "        z = z**2 + c\n",
    "        diverge = z.real**2 + z.imag**2 > 2**2\n",
    "        divnow = diverge & (fractal == maxiterations)\n",
    "        fractal[divnow] = i\n",
    "        z[diverge] = 2\n",
    "    return fractal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can make effective use of vector units because it's always applying the <b>S</b>ame <b>I</b>nstruction on <b>M</b>ultiple <b>D</b>ata (SIMD)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All we need is a librrary to implement the Numpy functions on a GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cupy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.889005661010742"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c, fractal = prepare(4000, 6000)\n",
    "\n",
    "c = cupy.array(c)\n",
    "fractal = cupy.array(fractal)\n",
    "\n",
    "starttime = time.time()\n",
    "fractal = run(c, fractal)\n",
    "time.time() - starttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.4934611320495605"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c, fractal = prepare(4000, 6000)\n",
    "\n",
    "starttime = time.time()\n",
    "fractal = run(c, fractal)\n",
    "time.time() - starttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exactly the same code: first with CuPy on the GPU (2.8 sec), then with Numpy on the CPU (7.5 sec)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you're wondering why I'm working on a reduced problem (4 time smaller than previous sessions), it's because I couldn't fit the full one in my GPU's memory!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(There's always a catch!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, CuPy's adherence to the Numpy API isn't perfect: I had to write\n",
    "\n",
    "```python\n",
    "z.real**2 + z.imag**2\n",
    "```\n",
    "\n",
    "instead of\n",
    "\n",
    "```python\n",
    "numpy.absolute(z)\n",
    "```\n",
    "\n",
    "because the `absolute` function wasn't supported. This is the error you'd see:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "object __array__ method not producing an array\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    numpy.absolute(cupy.array([1.1, 2.2, 3.3]))\n",
    "except ValueError as err:\n",
    "    print(err)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nevertheless, we can expect CuPy to become more complete as people use it and report bugs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**GPU method #2:** Use Numba! (You have to install a \"cudatoolkit\" library with it.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba.cuda\n",
    "\n",
    "@numba.cuda.jit\n",
    "def as_cuda(c, fractal, maxiterations):\n",
    "    x, y = numba.cuda.grid(2)     # 2 dimensional CUDA grid\n",
    "    z = c[x, y]\n",
    "    for i in range(maxiterations):\n",
    "        z = z**2 + c[x, y]\n",
    "        if abs(z) > 2:\n",
    "            fractal[x, y] = i\n",
    "            break                 # not optimal: threads that leave the loop still have to wait\n",
    "\n",
    "def run_numba(height, width, maxiterations=20):\n",
    "    y, x = numpy.ogrid[-1:0:height*1j, -1.5:0:width*1j]\n",
    "    c = x + y*1j\n",
    "    fractal = numpy.zeros(c.shape, dtype=numpy.int32) + maxiterations\n",
    "    return as_cuda(c, fractal, maxiterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.49817538261413574"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "fractal = run_numba(4000, 6000)\n",
    "time.time() - starttime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the same sized problem,\n",
    "\n",
    "   * Numpy on the CPU: 7.5 sec\n",
    "   * CuPy on the GPU: 2.8 sec\n",
    "   * Numba on the GPU: 0.5 sec\n",
    "\n",
    "And Numba doesn't suffer from the memory issue because it doesn't make as many intermediate copies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.278907060623169"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "starttime = time.time()\n",
    "fractal = run_numba(8000, 12000)    # full-sized problem\n",
    "time.time() - starttime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
